# AI Service Configuration
# Choose AI provider: 'openrouter', 'openai', or 'ollama'
AI_MODEL_PROVIDER=openrouter

# Model name (must match the exact model name from your provider)
# For OpenRouter: google/gemini-2.0-flash-exp:free, anthropic/claude-3-sonnet, etc.
# For OpenAI: gpt-4o-mini, gpt-4o, gpt-3.5-turbo, etc.
# For Ollama: llama2, codellama, etc.
AI_MODEL_NAME=google/gemini-2.0-flash-exp:free

# Base URL for AI service (optional, uses provider defaults if not set)
# OpenRouter: https://openrouter.ai/api/v1 (default)
# OpenAI: https://api.openai.com/v1 (default)
# Ollama: http://localhost:11434/v1 (default)
AI_MODEL_BASE_URL=https://openrouter.ai/api/v1

# AI Generation Parameters
AI_TEMPERATURE=0.3
AI_MAX_TOKENS=2000

# API Keys (set the one matching your AI_MODEL_PROVIDER)
OPENROUTER_API_KEY=your_openrouter_api_key_here
OPENAI_API_KEY=your_openai_api_key_here

# AI Estimation Settings (percentages for automatic breakdown generation)
AI_TESTING_PERCENTAGE=20
AI_BUGFIXING_PERCENTAGE=10
AI_DEFAULT_WORKDAY_HOURS=8

# System Environment
NODE_ENV=production