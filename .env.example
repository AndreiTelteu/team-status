# AI Provider Configuration for Breakdown Generation
# Choose your preferred AI provider and configure accordingly

# OpenRouter Configuration (recommended for diverse model access)
# Get your API key from: https://openrouter.ai/
AI_MODEL_PROVIDER=openrouter
AI_MODEL_NAME=google/gemini-2.0-flash-exp
AI_MODEL_BASE_URL=https://openrouter.ai/api/v1
OPENROUTER_API_KEY=your_openrouter_api_key_here

# Alternative: OpenAI Configuration
# AI_MODEL_PROVIDER=openai
# AI_MODEL_NAME=gpt-4o-mini
# OPENAI_API_KEY=your_openai_api_key_here

# Alternative: Anthropic Configuration (via OpenRouter)
# AI_MODEL_PROVIDER=openrouter
# AI_MODEL_NAME=anthropic/claude-3-5-sonnet-20241022
# AI_MODEL_BASE_URL=https://openrouter.ai/api/v1
# OPENROUTER_API_KEY=your_openrouter_api_key_here

# Alternative: Local Ollama Configuration
# AI_MODEL_PROVIDER=ollama
# AI_MODEL_NAME=llama3.1:8b
# AI_MODEL_BASE_URL=http://localhost:11434/v1

# Model Configuration Options
AI_MAX_TOKENS=2000
AI_TEMPERATURE=0.3
AI_TOP_P=0.9

# Breakdown Generation Settings
AI_INCLUDE_TESTING_MODULE=true
AI_TESTING_PERCENTAGE=20
AI_BUGFIXING_PERCENTAGE=10
AI_DEFAULT_WORKDAY_HOURS=8